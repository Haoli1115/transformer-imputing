{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "import statsmodels.api as sm\n",
    "from math import sqrt as math_sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Import custom modules\n",
    "sys.path.append('../')\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.4.1\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data, testing_index = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries, no_features, feature_names, years, months, weekdays, hours = load_data_information()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts features, year, etc. from whole data\n",
    "def change_format(input_data):\n",
    "    #Extract year from data matrix\n",
    "    year_w = input_data[:,:,0:1]\n",
    "    #Extract weekday from data matrix\n",
    "    weekday_w = input_data[:,:,1:2]\n",
    "    #Extract hour from data matrix\n",
    "    hour_w = input_data[:,:,2:3]\n",
    "    #Extract country from data matrix\n",
    "    country_w = input_data[:,0:1,3]   \n",
    "    #Extract month from data matrix\n",
    "    month_w = input_data[:,:,4:5]\n",
    "    #Extract features from matrix\n",
    "    features_w = input_data[:,:,5:5+no_features]\n",
    "    #Extract matrix of missing values from data matrix\n",
    "    miss_vals_w = input_data[:,:,-no_features-6:-6]\n",
    "    #Extract pos enc from data matrix\n",
    "    pos_enc_w = input_data[:,:,-6:]\n",
    "\n",
    "\n",
    "    #Prepare format for features\n",
    "    features_tf = np.reshape(features_w, [features_w.shape[0], -1, 1])\n",
    "    miss_vals_tf = np.reshape(miss_vals_w, [features_w.shape[0], -1, 1])\n",
    "    pos_enc_tf = np.reshape(tf.transpose(np.repeat(np.reshape(pos_enc_w, [pos_enc_w.shape[0], pos_enc_w.shape[1], pos_enc_w.shape[2], 1]), no_features, axis = 3), perm=[0,1,3,2]),[pos_enc_w.shape[0],-1,pos_enc_w.shape[2]])\n",
    "    feature_nr_tf = np.repeat(np.reshape(np.repeat(np.reshape(np.array(range(no_features)),[1,-1]), input_data.shape[1], axis = 0),[1,-1]), input_data.shape[0], axis = 0)\n",
    "    \n",
    "    #Reshape other features\n",
    "    hour_tf = np.reshape(np.repeat(hour_w, no_features,axis=2),[input_data.shape[0],-1])\n",
    "    year_tf = np.reshape(np.repeat(year_w, no_features,axis=2),[input_data.shape[0],-1])\n",
    "    weekday_tf = np.reshape(np.repeat(weekday_w, no_features,axis=2),[input_data.shape[0],-1])\n",
    "    month_tf = np.reshape(np.repeat(month_w, no_features,axis=2),[input_data.shape[0],-1])\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    return features_tf, miss_vals_tf, pos_enc_tf, country_w, year_tf, weekday_tf, hour_tf, feature_nr_tf\n",
    "#testing\n",
    "features, miss_vals, pos_enc, country, year, weekday, hour, feature_nr = change_format(training_data[18:19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anpassen der Anzahl der missing values und welches feature gemasked werden soll\n",
    "\n",
    "Features: PV-12 ; Wind-Onshore-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_miss_vals = no_features*12#24 # number of missing values per day (maximum is features masked times 24)\n",
    "masked_feature = 12 # country and year do not count\n",
    "all_masked = 1# if all inserted features should be masked randomly (if 1, masked feature is not needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion um Maske Ã¼ber Features zu legen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_features(features, miss_vals):    \n",
    "    mask = np.zeros(features.shape)\n",
    "    for sample in range(features.shape[0]):\n",
    "        if all_masked == 1:        \n",
    "            #Draw number of missing values from Binomial distribution\n",
    "            p = np.random.uniform(0.2,0.8)\n",
    "            n_miss_vals = np.random.binomial(n=24*no_features, p = p)\n",
    "            idx_all = list(range(24*no_features)) # all features masked\n",
    "        else:\n",
    "            n_miss_vals = number_miss_vals\n",
    "            idx_all = list(range(masked_feature,24*no_features,no_features)) # just one feature masked\n",
    "        np.random.shuffle(idx_all)\n",
    "        idx = idx_all[:n_miss_vals]\n",
    "        for mv in range(n_miss_vals):\n",
    "            #Insert mask at the middle day of the week\n",
    "            mask[sample, (2*24)*no_features + idx[mv]] = 1\n",
    "\n",
    "    features_masked = np.array(features)\n",
    "    features_masked[mask==1] = 0\n",
    "\n",
    "    miss_vals_masked = np.array(miss_vals)\n",
    "    miss_vals_masked[mask==1] = 1\n",
    "    \n",
    "\n",
    "    return features_masked, miss_vals_masked, mask\n",
    "features_masked, miss_vals_masked, mask = mask_features(features, miss_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation split and fetch data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create function for validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_split(data, split = 0.2):\n",
    "    size = int(data.shape[0]*split)\n",
    "    index = data.shape[0]\n",
    "    split_index = random.choices(range(index),k=size)\n",
    "    data_val = data[split_index]\n",
    "    data_train = np.delete(data,split_index,axis=0)\n",
    "    \n",
    "    return data_train, data_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define batch size and create preprocessing for testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead) \n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        mask = tf.cast(mask, dtype = tf.float32)\n",
    "        scaled_attention_logits = scaled_attention_logits + (mask * -1e9)  \n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, q, k, v, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights= scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, q, kv, training, mask):\n",
    "\n",
    "        attn_output, attention_weights = self.mha(q, kv, kv, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(attn_output+q)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        \n",
    "    def call(self, q, kv, training, mask):\n",
    "        for i in range(self.num_layers):\n",
    "            q, attention_weights = self.enc_layers[i](q, kv, training, mask)\n",
    "\n",
    "        return q, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heuristik fÃ¼r Anzahl Embedding AusgÃ¤nge\n",
    "\n",
    "min(600, round(1.6 * (config[\"vocab_size\"] + 1) ** .56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, no_features, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        #Encoding Layers\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, rate)\n",
    "        \n",
    "        #Embedding layers\n",
    "        self.embedding_country = tf.keras.layers.Embedding(countries.shape[0], 9)\n",
    "        self.embedding_year = tf.keras.layers.Embedding(years.shape[0], 4) \n",
    "        self.embedding_feat = tf.keras.layers.Embedding(no_features, 7)\n",
    "        \n",
    "\n",
    "        #Dense Layers\n",
    "        self.first_layer = tf.keras.layers.Dense(d_model)\n",
    "        self.final_layer = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, country, year, weekday, hour, features_masked, miss_vals_masked, \n",
    "            pos_enc, feature_nr, training, enc_padding_mask = None):\n",
    "          \n",
    "        #Embeddings\n",
    "        country_emb = self.embedding_country(country)\n",
    "        year_emb = self.embedding_year(year)\n",
    "        #weekday_emb = self.embedding_weekday(weekday)\n",
    "        #hour_emb = self.embedding_hour(hour)\n",
    "        feat_emb = self.embedding_feat(feature_nr)\n",
    "        \n",
    "        \n",
    "        # concatenation (embeddings plus features)\n",
    "        kv = tf.concat([pos_enc, \n",
    "                        tf.repeat(country_emb, pos_enc.shape[1], axis = 1),\n",
    "                        year_emb, \n",
    "                        #weekday_emb, \n",
    "                        #hour_emb,\n",
    "                        features_masked, miss_vals_masked, feat_emb], axis = 2)\n",
    "        kv = self.first_layer(kv)\n",
    "\n",
    "        q = tf.concat([pos_enc, \n",
    "                       tf.repeat(country_emb, pos_enc.shape[1], axis = 1),\n",
    "                       year_emb, \n",
    "                       #weekday_emb,  \n",
    "                       #hour_emb,\n",
    "                       features_masked, miss_vals_masked, feat_emb], axis = 2)\n",
    "        q = self.first_layer(q)\n",
    "        \n",
    "        enc_output, attention_weights = self.encoder(q, kv, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        final_output = self.final_layer(enc_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss and Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred, mask):\n",
    "    real = real[mask==1]\n",
    "    pred = pred[mask==1]\n",
    "    real = tf.dtypes.cast(real, tf.float32)\n",
    "    error = real-pred\n",
    "    error = tf.square(error)\n",
    "    loss = tf.math.sqrt(tf.math.reduce_mean(error))*1000 # sonst so klein ;-)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 2*d_model\n",
    "num_heads = 1\n",
    "dropout_rate = 0.1\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(country, year, weekday, hour, features, features_masked, miss_vals_masked, \n",
    "               pos_enc, feature_nr, mask):\n",
    "\n",
    "    training = True\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred, attention_weights = transformer(country, year, weekday, hour, features_masked, miss_vals_masked, \n",
    "                                              pos_enc, feature_nr,  training)\n",
    "\n",
    "        loss = loss_function(features, pred, mask)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    return loss, pred, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff, no_features, rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpointing\n",
    "\n",
    "Checkpoint manager kann genutzt werden um trainierte Modelle zu speichern und zu laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./checkpoints/transformer\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scheduler:\n",
    "    def __init__(self, checkpoint, checkpoint_manager, learning_rate, patience = 2, delta = 5, fine_tuning = False, min_epochs = 20):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.delta = delta\n",
    "        self.checkpoint_manager = checkpoint_manager\n",
    "        self.checkpoint = checkpoint\n",
    "        self.learning_rate = learning_rate\n",
    "        self.fine_tuning = fine_tuning\n",
    "        self.min_epochs = min_epochs\n",
    "\n",
    "    def __call__(self, metric, epoch):\n",
    "        #Check if score is not initialized\n",
    "        if self.best_score is None:\n",
    "            self.best_score = metric\n",
    "            return (False,self.learning_rate)\n",
    "        \n",
    "        #Check for minimum amount of epochs\n",
    "        if epoch <= self.min_epochs:\n",
    "            if metric <= self.best_score + self.delta:\n",
    "                self.best_score = metric\n",
    "                ckpt_save_path = self.checkpoint_manager.save()\n",
    "                print(f'Saving checkpoint at {ckpt_save_path}')\n",
    "            return (False, self.learning_rate)\n",
    "        \n",
    "        #If score is worse than before\n",
    "        if metric > self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            #If score is still in patience\n",
    "            if self.counter >= self.patience:\n",
    "                #If fine tuning is already running\n",
    "                if self.fine_tuning==True:\n",
    "                    print(\"Training finished\")\n",
    "                    return (True,self.learning_rate)\n",
    "                else:\n",
    "                    self.fine_tuning=True\n",
    "                    self.counter = 0\n",
    "                    self.learning_rate = self.learning_rate/2\n",
    "                    self.patience += 2\n",
    "                    if self.checkpoint_manager.latest_checkpoint:\n",
    "                        self.checkpoint.restore(self.checkpoint_manager.latest_checkpoint)\n",
    "                        print('Latest checkpoint restored!!')\n",
    "                    print(f'Learning rate adjusted to {np.round(self.learning_rate,6)}')\n",
    "                    self.patience +=2\n",
    "                    return (False,self.learning_rate)\n",
    "            else:                \n",
    "                return (False,self.learning_rate)\n",
    "        #If score is better   \n",
    "        else:\n",
    "            self.best_score = metric\n",
    "            ckpt_save_path = self.checkpoint_manager.save()\n",
    "            print(f'Saving checkpoint at {ckpt_save_path}')\n",
    "            self.counter = 0        \n",
    "            return (False,self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = Scheduler(ckpt, ckpt_manager, learning_rate, patience = 5, delta = 5, fine_tuning=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/transformer/\"\n",
    "train_writer = tf.summary.create_file_writer(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 8080 (pid 33040), started 0:05:25 ago. (Use '!kill 33040' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5d300e5b0bf9078b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5d300e5b0bf9078b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8080;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/transformer --port=8080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading..:   3%|âââ                                                                  | 69/2161 [00:17<08:50,  3.94it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30368/875736732.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mfeatures_masked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmiss_vals_masked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmiss_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         loss, pred, attention_weights = train_step(country, year, weekday, hour, features, features_masked,\n\u001b[0m\u001b[0;32m     41\u001b[0m                                                 miss_vals_masked, pos_enc, feature_nr, mask)\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30368/4272395471.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(country, year, weekday, hour, features, features_masked, miss_vals_masked, pos_enc, feature_nr, mask)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1078\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1081\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    267\u001b[0m     factor = _safe_shape_div(\n\u001b[0;32m    268\u001b[0m         math_ops.reduce_prod(input_shape), math_ops.reduce_prod(output_shape))\n\u001b[1;32m--> 269\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruediv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mtruediv\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1334\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m   \"\"\"\n\u001b[1;32m-> 1336\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_truediv_python3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_truediv_python3\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1273\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1275\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal_div\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mreal_div\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   7322\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7323\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7324\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   7325\u001b[0m         _ctx, \"RealDiv\", name, x, y)\n\u001b[0;32m   7326\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "losses = [[],[]]\n",
    "\n",
    "for epoch in range(EPOCHS):    \n",
    "\n",
    "    #Create a smaller sample of the training data for computational purposes\n",
    "    #Only while testing the model\n",
    "    #index = random.choices(range(training_data.shape[0]),k=1000)\n",
    "    #train_res = training_data[index]\n",
    "    \n",
    "    #Shuffle training data\n",
    "    #np.random.shuffle(training_data)\n",
    "    \n",
    "    # split train data in train and val sets\n",
    "    samples_train, samples_val = val_split(training_data,split=0.2)\n",
    "\n",
    "    # create train dataset\n",
    "    data_train = tf.data.Dataset.from_tensor_slices(samples_train)\n",
    "    data_train = data_train.cache()\n",
    "    data_train = data_train.shuffle(samples_train.shape[0]).padded_batch(BATCH_SIZE) #, drop_remainder=True\n",
    "    data_train = data_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # create val dataset \n",
    "    data_val = tf.data.Dataset.from_tensor_slices(samples_val)\n",
    "    data_val = data_val.cache()\n",
    "    data_val = data_val.shuffle(samples_val.shape[0]).padded_batch(BATCH_SIZE) #, drop_remainder=True\n",
    "    data_val = data_val.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    val_loss.reset_states()\n",
    "    \n",
    "    train_counter = 0\n",
    "    running_train_loss = 0  \n",
    "    # train the model\n",
    "    for (batch, data_inp) in tqdm(enumerate(data_train), desc = \"Loading..\", total = int(np.ceil(samples_train.shape[0]/BATCH_SIZE))):\n",
    "        train_counter += 1\n",
    "        features, miss_vals, pos_enc, country, year, weekday, hour, feature_nr = change_format(data_inp)\n",
    "        features_masked, miss_vals_masked, mask = mask_features(features, miss_vals)\n",
    "\n",
    "        loss, pred, attention_weights = train_step(country, year, weekday, hour, features, features_masked,\n",
    "                                                miss_vals_masked, pos_enc, feature_nr, mask)\n",
    "        \n",
    "        #Save loss to tensorboard\n",
    "        running_train_loss += loss\n",
    "        if train_counter % 100 == 0:\n",
    "            with train_writer.as_default():\n",
    "                tf.summary.scalar('train_loss', running_train_loss/100, step=(epoch*len(samples_train)+train_counter*BATCH_SIZE))\n",
    "                running_train_loss = 0\n",
    "\n",
    "        train_loss(loss)\n",
    "    losses[0].append(train_loss.result())\n",
    "\n",
    "\n",
    "    # validation data calculation\n",
    "    for (batch, data_inp) in enumerate(data_val):\n",
    "        features, miss_vals, pos_enc, country, year, weekday, hour, feature_nr= change_format(data_inp)\n",
    "        features_masked, miss_vals_masked, mask = mask_features(features, miss_vals)\n",
    "\n",
    "        pred,_ = transformer(country, year, weekday, hour, features_masked, miss_vals_masked,\n",
    "                            pos_enc, feature_nr, training=False)\n",
    "        loss = loss_function(features, pred, mask)\n",
    "        val_loss(loss)\n",
    "    losses[1].append(val_loss.result())\n",
    "    \n",
    "    #Save validation data to log\n",
    "    with train_writer.as_default():\n",
    "        tf.summary.scalar('val_loss', val_loss.result(), step=((epoch+1)*len(samples_train)))\n",
    "\n",
    "    print ('Epoch {} - Loss {:.4f} val_Loss {:.4f} '.format(\n",
    "        epoch + 1, train_loss.result(), val_loss.result()))\n",
    "\n",
    "    #Check early stopping and checkpointing\n",
    "    stopping, learning_rate = scheduler(float(val_loss.result()), epoch)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "    if stopping == True:\n",
    "        if ckpt_manager.latest_checkpoint:\n",
    "            ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "            print(\"Training finished\")      \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_2 (Encoder)          multiple                  529920    \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      multiple                  261       \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      multiple                  24        \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      multiple                  91        \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             multiple                  3712      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             multiple                  129       \n",
      "=================================================================\n",
      "Total params: 534,137\n",
      "Trainable params: 534,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x296d75fcdf0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses[0])\n",
    "plt.plot(losses[1])\n",
    "plt.legend([\"Training loss\",\"Validation loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x24effac9cd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.load_weights('weights/transformer/transformer_weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test data\n",
    "\n",
    "Modell wird noch einmal auf finalen Testdatensatz angewandt. Dann kann der Testdatensatz extrahiert werden um ihn fÃ¼r die anderen Modelle zum Benchmarking zu benutzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BATCH_SIZE = 32\n",
    "data_test = tf.data.Dataset.from_tensor_slices(testing_data)\n",
    "data_test = data_test.cache()\n",
    "data_test = data_test.padded_batch(BATCH_SIZE)\n",
    "data_test = data_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing process: Testing mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for testing mask\n",
    "def get_testing_mask(features, miss_vals, mask):\n",
    "    mask = mask.reshape(features.shape)\n",
    "    features_masked = np.array(features)\n",
    "    features_masked[mask==1] = 0\n",
    "\n",
    "    miss_vals_masked = np.array(miss_vals)\n",
    "    miss_vals_masked[mask==1] = 1\n",
    "\n",
    "    \n",
    "    return features_masked, miss_vals_masked, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and predict testing masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading..: 100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 259/259 [00:20<00:00, 12.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015422470266553029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading..: 100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 259/259 [00:20<00:00, 12.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016661310697099942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading..: 100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 259/259 [00:23<00:00, 10.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016855987827722647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading..: 100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 259/259 [00:20<00:00, 12.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018851196446613743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading..: 100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 259/259 [00:20<00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020926213949660575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading..: 100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 259/259 [00:20<00:00, 12.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023508593595606964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading..: 100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 259/259 [00:20<00:00, 12.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027032873230646955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading..: 100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 259/259 [00:21<00:00, 12.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03423005040619691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading..: 100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 259/259 [00:21<00:00, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.045837955661024624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for p in np.round(np.arange(0.1,1,0.1),1):\n",
    "    testing_mask=np.load(\"../evaluation/masks/testing_mask_{}.npy\".format(p))\n",
    "    \n",
    "    #Create empty arrays for Results\n",
    "    values_act=np.array([])\n",
    "    prediction = np.array([])\n",
    "\n",
    "    for (batch, data_inp) in tqdm(enumerate(data_test), desc = \"Loading..\", total = int(np.ceil(testing_data.shape[0]/BATCH_SIZE))):\n",
    "        features, miss_vals, pos_enc, country, year, weekday, hour, feature_nr= change_format(data_inp)\n",
    "        features_masked, miss_vals_masked, mask = get_testing_mask(features, miss_vals, testing_mask[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE])\n",
    "\n",
    "        pred,attention_weights = transformer(country, year, weekday, hour, features_masked, miss_vals_masked, \n",
    "                            pos_enc, feature_nr, training=False)\n",
    "\n",
    "        #Add real values and prediction to dataframe\n",
    "        values_act = np.append(values_act,features[mask==1].flatten())\n",
    "        prediction = np.append(prediction,pred[mask==1].numpy())\n",
    "        \n",
    "    #Calculate mse\n",
    "    mse = mean_squared_error(values_act,prediction)\n",
    "    print(mse)\n",
    "    \n",
    "    #Save prediction\n",
    "    np.save(\"../data/predictions/transformer_pred_{}\".format(p),prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading..:   0%|                                                                               | 0/259 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 28800 into shape (20,1560,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30572/3369237299.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_inp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Loading..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmiss_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_enc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcountry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweekday\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhour\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_nr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchange_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_inp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mfeatures_masked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmiss_vals_masked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_testing_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmiss_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesting_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     pred,attention_weights = transformer(country, year, weekday, hour, features_masked, miss_vals_masked, \n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30572/2943831176.py\u001b[0m in \u001b[0;36mget_testing_mask\u001b[1;34m(features, miss_vals, mask)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Function for testing mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_testing_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmiss_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mfeatures_masked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfeatures_masked\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 28800 into shape (20,1560,1)"
     ]
    }
   ],
   "source": [
    "#Load testing mask\n",
    "testing_mask=np.load(\"../data/evaluation/testing_mask_test.npy\")\n",
    "#Create empty arrays for Results\n",
    "prediction = np.array([])\n",
    "values_act=np.array([])\n",
    "\n",
    "\n",
    "for (batch, data_inp) in tqdm(enumerate(data_test), desc = \"Loading..\", total = int(np.ceil(testing_data.shape[0]/BATCH_SIZE))):\n",
    "    features, miss_vals, pos_enc, country, year, weekday, hour, feature_nr = change_format(data_inp)\n",
    "    features_masked, miss_vals_masked, mask = get_testing_mask(features, miss_vals, testing_mask[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE])\n",
    "\n",
    "    pred,attention_weights = transformer(country, year, weekday, hour, features_masked, miss_vals_masked, \n",
    "                        pos_enc, feature_nr, training=False)\n",
    "\n",
    "    #Add real values and prediction to dataframe\n",
    "    values_act = np.append(values_act,features[mask==1].flatten())\n",
    "    prediction = np.append(prediction,pred[mask==1].numpy())\n",
    "\n",
    "#Print mse\n",
    "mse = mean_squared_error(values_act,prediction)\n",
    "print(mse)\n",
    "\n",
    "np.save(\"../data/predictions/transformer_pred_test\",prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
